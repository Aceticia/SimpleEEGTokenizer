# @package _global_
training:
  # Optimizer parameters
  learning_rate: 0.001
  weight_decay: 0.00001
  
  # Scheduler parameters
  warmup_epochs: 10
  max_steps: 100000
  warmup_start_lr: 0.000001
  eta_min: 0.000001

  # Logging parameters
  log_every_n_steps: 50
  checkpoint_every_n_steps: 5000

  # Validation
  val_check_interval: 5000
  precision: 16-mixed